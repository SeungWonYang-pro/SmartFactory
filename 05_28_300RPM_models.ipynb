{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpS0hs+IYn6VeXWAnd9wGW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-ANWy4RozvC",
        "outputId": "1c66c32c-d712-46c5-f6d8-bf4d046fbe4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install seaborn\n",
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "!pip install scikit-learn\n",
        "!pip install torch_geometric\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "O-SaSbjBoznO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95394c3-1d59-4824-dbaa-450bad6fc05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, VGAE\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import train_test_split_edges, to_undirected\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import stft\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "# 데이터 파일 로드 및 정규화\n",
        "\n",
        "def normalize_data(df):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(df)\n",
        "\n",
        "def load_and_normalize_data(filenames, label):\n",
        "    data_list = []\n",
        "    for filename in filenames:\n",
        "        df = pd.read_csv(filename)\n",
        "        motor_data_normalized = normalize_data(df[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "        sound_data_normalized = normalize_data(df[['sound']])\n",
        "        data_list.append((motor_data_normalized, sound_data_normalized, label))\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "iUm3vRShpFkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"drive/MyDrive/Colab Notebooks/SmartFactory/csv/5000hz/300rpm/\"\n",
        "\n",
        "normal_files = [path+\"300rpm normal data/stream2024_4_22_23_27.csv\"]\n",
        "fault1_files = [path+\"300rpm carriage damage/stream2024_4_23_3_1.csv\"]\n",
        "fault2_files = [path+\"300rpm high-speed damage/stream2024_4_23_0_24.csv\"]\n",
        "fault3_files = [path+\"300rpm lack of lubrication/stream2024_4_23_2_10.csv\"]\n",
        "fault4_files = [path+\"300rpm oxidation and corrosion/stream2024_4_23_1_19.csv\"]\n",
        "\n",
        "data_normal = load_and_normalize_data(normal_files, 0)\n",
        "data_fault1 = load_and_normalize_data(fault1_files, 1)\n",
        "data_fault2 = load_and_normalize_data(fault2_files, 2)\n",
        "data_fault3 = load_and_normalize_data(fault3_files, 3)\n",
        "data_fault4 = load_and_normalize_data(fault4_files, 4)\n",
        "\n",
        "all_data = data_normal + data_fault1 + data_fault2 + data_fault3 + data_fault4"
      ],
      "metadata": {
        "id": "cCsB7vG9o7Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 데이터 파일 로드\n",
        "normal_data = pd.read_csv(path+\"300rpm normal data/stream2024_4_22_23_27.csv\")\n",
        "carriage_data = pd.read_csv(path+\"300rpm carriage damage/stream2024_4_23_3_1.csv\")\n",
        "highspeed_data = pd.read_csv(path+\"300rpm high-speed damage/stream2024_4_23_0_24.csv\")\n",
        "lack_data = pd.read_csv(path+\"300rpm lack of lubrication/stream2024_4_23_2_10.csv\")\n",
        "corrosion_data = pd.read_csv(path+\"300rpm oxidation and corrosion/stream2024_4_23_1_19.csv\")\n",
        "\n",
        "# 데이터 정규화 함수 정의\n",
        "def normalize_data(df):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(df)\n",
        "\n",
        "# 모터 및 소리 데이터 정규화\n",
        "normal_motor_data_normalized = normalize_data(normal_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "normal_sound_data_normalized = normalize_data(normal_data[['sound']])\n",
        "carriage_motor_data_normalized = normalize_data(carriage_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "carriage_sound_data_normalized = normalize_data(carriage_data[['sound']])\n",
        "highspeed_motor_data_normalized = normalize_data(highspeed_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "highspeed_sound_data_normalized = normalize_data(highspeed_data[['sound']])\n",
        "lack_motor_data_normalized = normalize_data(lack_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "lack_sound_data_normalized = normalize_data(lack_data[['sound']])\n",
        "corrosion_motor_data_normalized = normalize_data(corrosion_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "corrosion_sound_data_normalized = normalize_data(corrosion_data[['sound']])\n",
        "\n",
        "# 데이터 합치기\n",
        "def concatenate_data(motor_data, sound_data):\n",
        "    return np.hstack((motor_data, sound_data))\n",
        "\n",
        "X_normal = concatenate_data(normal_motor_data_normalized, normal_sound_data_normalized)\n",
        "X_carriage = concatenate_data(carriage_motor_data_normalized, carriage_sound_data_normalized)\n",
        "X_highspeed = concatenate_data(highspeed_motor_data_normalized, highspeed_sound_data_normalized)\n",
        "X_lack = concatenate_data(lack_motor_data_normalized, lack_sound_data_normalized)\n",
        "X_corrosion = concatenate_data(corrosion_motor_data_normalized, corrosion_sound_data_normalized)\n",
        "\n",
        "# 레이블 생성\n",
        "y_normal = np.zeros(X_normal.shape[0])\n",
        "y_carriage = np.ones(X_carriage.shape[0])\n",
        "y_highspeed = np.full((X_highspeed.shape[0],), 2)\n",
        "y_lack = np.full((X_lack.shape[0],), 3)\n",
        "y_corrosion = np.full((X_corrosion.shape[0],), 4)\n",
        "\n",
        "# 데이터셋 합치기\n",
        "X = np.vstack((X_normal, X_carriage, X_highspeed, X_lack, X_corrosion))\n",
        "y = np.concatenate((y_normal, y_carriage, y_highspeed, y_lack, y_corrosion))\n",
        "\n",
        "# 레이블을 원-핫 인코딩으로 변환\n",
        "y = to_categorical(y)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "timesteps = 1\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# 데이터 형태 변환\n",
        "X_train = X_train.reshape(X_train.shape[0], timesteps, input_dim)\n",
        "X_test = X_test.reshape(X_test.shape[0], timesteps, input_dim)\n",
        "\n",
        "# LSTM 모델 정의\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(timesteps, input_dim), activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# 얼리스탑 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_true_classes, y_pred_classes,digits=4))"
      ],
      "metadata": {
        "id": "Q2ZN51oxmUGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2066b78f-56f0-4bba-c075-56fed799767b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 128)            68096     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1, 64)             49408     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132357 (517.02 KB)\n",
            "Trainable params: 132357 (517.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4688/4688 [==============================] - 71s 12ms/step - loss: 1.0672 - accuracy: 0.4957 - val_loss: 0.5606 - val_accuracy: 0.7666\n",
            "Epoch 2/10\n",
            "4688/4688 [==============================] - 59s 13ms/step - loss: 0.4683 - accuracy: 0.7877 - val_loss: 0.3050 - val_accuracy: 0.8641\n",
            "Epoch 3/10\n",
            "4688/4688 [==============================] - 62s 13ms/step - loss: 0.3288 - accuracy: 0.8433 - val_loss: 0.2838 - val_accuracy: 0.8632\n",
            "Epoch 4/10\n",
            "4688/4688 [==============================] - 59s 12ms/step - loss: 0.3153 - accuracy: 0.8522 - val_loss: 0.2346 - val_accuracy: 0.9108\n",
            "Epoch 5/10\n",
            "4688/4688 [==============================] - 57s 12ms/step - loss: 0.2725 - accuracy: 0.8702 - val_loss: 0.2085 - val_accuracy: 0.8936\n",
            "Epoch 6/10\n",
            "4688/4688 [==============================] - 59s 13ms/step - loss: 0.2504 - accuracy: 0.8775 - val_loss: 0.2588 - val_accuracy: 0.8581\n",
            "Epoch 7/10\n",
            "4688/4688 [==============================] - 57s 12ms/step - loss: 0.2453 - accuracy: 0.8804 - val_loss: 0.1877 - val_accuracy: 0.8989\n",
            "Epoch 8/10\n",
            "4688/4688 [==============================] - 59s 13ms/step - loss: 0.2400 - accuracy: 0.8803 - val_loss: 0.1894 - val_accuracy: 0.8918\n",
            "Epoch 9/10\n",
            "4688/4688 [==============================] - 60s 13ms/step - loss: 0.2313 - accuracy: 0.8825 - val_loss: 0.1750 - val_accuracy: 0.9055\n",
            "Epoch 10/10\n",
            "4688/4688 [==============================] - 58s 12ms/step - loss: 0.2147 - accuracy: 0.8909 - val_loss: 0.2518 - val_accuracy: 0.8744\n",
            "9375/9375 [==============================] - 25s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8404    0.9486    0.8912     59643\n",
            "           1     0.9094    0.9344    0.9217     59988\n",
            "           2     0.9430    0.9515    0.9473     60001\n",
            "           3     0.8160    0.7226    0.7665     60196\n",
            "           4     0.8584    0.8159    0.8366     60172\n",
            "\n",
            "    accuracy                         0.8744    300000\n",
            "   macro avg     0.8734    0.8746    0.8727    300000\n",
            "weighted avg     0.8734    0.8744    0.8725    300000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM AE\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.signal\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed, Input, LeakyReLU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 파일 로드\n",
        "normal_data = pd.read_csv(path+\"300rpm normal data/stream2024_4_22_23_27.csv\")\n",
        "carriage_data = pd.read_csv(path+\"300rpm carriage damage/stream2024_4_23_3_1.csv\")\n",
        "highspeed_data = pd.read_csv(path+\"300rpm high-speed damage/stream2024_4_23_0_24.csv\")\n",
        "lack_data = pd.read_csv(path+\"300rpm lack of lubrication/stream2024_4_23_2_10.csv\")\n",
        "corrosion_data = pd.read_csv(path+\"300rpm oxidation and corrosion/stream2024_4_23_1_19.csv\")\n",
        "\n",
        "# 데이터 정규화 함수 정의\n",
        "def normalize_data(df):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(df)\n",
        "def concatenate_data(motor_data, sound_data):\n",
        "    return np.hstack((motor_data, sound_data))\n",
        "\n",
        "# 모터 및 소리 데이터 정규화\n",
        "normal_motor_data_normalized = normalize_data(normal_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "normal_sound_data_normalized = normalize_data(normal_data[['sound']])\n",
        "carriage_motor_data_normalized = normalize_data(carriage_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "carriage_sound_data_normalized = normalize_data(carriage_data[['sound']])\n",
        "highspeed_motor_data_normalized = normalize_data(highspeed_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "highspeed_sound_data_normalized = normalize_data(highspeed_data[['sound']])\n",
        "lack_motor_data_normalized = normalize_data(lack_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "lack_sound_data_normalized = normalize_data(lack_data[['sound']])\n",
        "corrosion_motor_data_normalized = normalize_data(corrosion_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "corrosion_sound_data_normalized = normalize_data(corrosion_data[['sound']])\n",
        "\n",
        "X_normal = concatenate_data(normal_motor_data_normalized, normal_sound_data_normalized)\n",
        "X_carriage = concatenate_data(carriage_motor_data_normalized, carriage_sound_data_normalized)\n",
        "X_highspeed = concatenate_data(highspeed_motor_data_normalized, highspeed_sound_data_normalized)\n",
        "X_lack = concatenate_data(lack_motor_data_normalized, lack_sound_data_normalized)\n",
        "X_corrosion = concatenate_data(corrosion_motor_data_normalized, corrosion_sound_data_normalized)\n",
        "\n",
        "\n",
        "# 레이블 생성\n",
        "y_normal = np.zeros(X_normal.shape[0])\n",
        "y_carriage = np.ones(X_carriage.shape[0])\n",
        "y_highspeed = np.full((X_highspeed.shape[0],), 2)\n",
        "y_lack = np.full((X_lack.shape[0],), 3)\n",
        "y_corrosion = np.full((X_corrosion.shape[0],), 4)\n",
        "\n",
        "# 데이터셋 합치기\n",
        "X = np.concatenate((X_normal, X_carriage, X_highspeed, X_lack, X_corrosion), axis=0)\n",
        "y = np.concatenate((y_normal, y_carriage, y_highspeed, y_lack, y_corrosion), axis=0)\n",
        "# 레이블을 원-핫 인코딩으로 변환\n",
        "y = to_categorical(y)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(\"Train data shape:\", X_train.shape)\n",
        "print(\"Test data shape:\", X_test.shape)\n",
        "\n",
        "# 데이터 형태 변환\n",
        "X_train = X_train.reshape(X_train.shape[0],-1, X_train.shape[1])  # (샘플 수, 시간, 특징 수)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1,X_test.shape[1])\n",
        "print(\"Train data shape after reshape:\", -1,X_train.shape)\n",
        "print(\"Test data shape after reshape:\", -1,X_test.shape)\n",
        "\n",
        "# LSTM Autoencoder 모델 정의\n",
        "def create_lstm_ae(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(LSTM(32, return_sequences=False))\n",
        "    model.add(RepeatVector(input_shape[0]))\n",
        "    model.add(LSTM(32, return_sequences=True))\n",
        "    model.add(LSTM(64, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(input_shape[1])))\n",
        "    return model\n",
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])  # (시간, 특징 수)\n",
        "model = create_lstm_ae(input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 얼리스탑 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "# 모델 훈련\n",
        "print(\"Training LSTM Autoencoder model...\")\n",
        "history = model.fit(X_train, X_train, epochs=1, batch_size=256, validation_data=(X_test, X_test), callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "# LSTM Autoencoder에서 인코딩된 특징 추출\n",
        "encoder = Sequential()\n",
        "encoder.add(model.layers[0])\n",
        "encoder.add(model.layers[1])\n",
        "encoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "X_train_encoded = encoder.predict(X_train)\n",
        "X_test_encoded = encoder.predict(X_test)\n",
        "\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(64, input_shape=(X_train_encoded.shape[1],)))\n",
        "classifier.add(LeakyReLU(alpha=0.01))  # Leaky ReLU 활성화 함수 사용\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(32))\n",
        "classifier.add(LeakyReLU(alpha=0.01))  # Leaky ReLU 활성화 함수 사용\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 다중 클래스 분류 모델 훈련\n",
        "print(\"Training classifier model...\")\n",
        "history = classifier.fit(X_train_encoded, y_train, epochs=1, batch_size=256, validation_data=(X_test_encoded, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# 테스트 데이터에 대한 예측 및 평가\n",
        "y_test_pred = classifier.predict(X_test_encoded)\n",
        "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
        "y_test_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Accuracy on test set:\", accuracy_score(y_test_true_classes, y_test_pred_classes))\n",
        "print(classification_report(y_test_true_classes, y_test_pred_classes, target_names=['Normal', 'Carriage Damage', 'High-Speed Damage', 'Lack of Lubrication', 'Oxidation and Corrosion'],digits=4))"
      ],
      "metadata": {
        "id": "ytu6DsUzm032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef0b95f-f1b8-462c-c9c2-be9dc2c1c276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (1200000, 4)\n",
            "Test data shape: (300000, 4)\n",
            "Train data shape after reshape: -1 (1200000, 1, 4)\n",
            "Test data shape after reshape: -1 (300000, 1, 4)\n",
            "Training LSTM Autoencoder model...\n",
            "4688/4688 [==============================] - 63s 12ms/step - loss: 0.0321 - val_loss: 3.2842e-05\n",
            "37500/37500 [==============================] - 91s 2ms/step\n",
            "9375/9375 [==============================] - 21s 2ms/step\n",
            "Training classifier model...\n",
            "4688/4688 [==============================] - 21s 4ms/step - loss: 1.5779 - accuracy: 0.2447 - val_loss: 1.5637 - val_accuracy: 0.2579\n",
            "9375/9375 [==============================] - 16s 2ms/step\n",
            "Accuracy on test set: 0.25787333333333334\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                 Normal     0.2551    0.2783    0.2662     59643\n",
            "        Carriage Damage     0.2132    0.0844    0.1209     59988\n",
            "      High-Speed Damage     0.2140    0.1249    0.1577     60001\n",
            "    Lack of Lubrication     0.2471    0.3624    0.2938     60196\n",
            "Oxidation and Corrosion     0.3003    0.4386    0.3565     60172\n",
            "\n",
            "               accuracy                         0.2579    300000\n",
            "              macro avg     0.2459    0.2577    0.2390    300000\n",
            "           weighted avg     0.2460    0.2579    0.2391    300000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHDDvS9CTjAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb30919-a47f-46ea-9bdc-2b08f9403351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Train Loss: 1.3458, Validation Loss: 1.1611\n",
            "Accuracy: 0.43376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9817    0.2780    0.4333     29650\n",
            "           1     0.9391    0.2867    0.4393     30079\n",
            "           2     0.4837    0.5459    0.5129     29969\n",
            "           3     0.3007    0.7423    0.4280     30220\n",
            "           4     0.3920    0.3126    0.3478     30082\n",
            "\n",
            "    accuracy                         0.4338    150000\n",
            "   macro avg     0.6194    0.4331    0.4323    150000\n",
            "weighted avg     0.6182    0.4338    0.4322    150000\n",
            "\n",
            "F1 Score (weighted): 0.4322\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#transformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv, VGAE\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import stft\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 데이터 파일 로드\n",
        "normal_data = pd.read_csv(path+\"300rpm normal data/stream2024_4_22_23_27.csv\")\n",
        "carriage_data = pd.read_csv(path+\"300rpm carriage damage/stream2024_4_23_3_1.csv\")\n",
        "highspeed_data = pd.read_csv(path+\"300rpm high-speed damage/stream2024_4_23_0_24.csv\")\n",
        "lack_data = pd.read_csv(path+\"300rpm lack of lubrication/stream2024_4_23_2_10.csv\")\n",
        "corrosion_data = pd.read_csv(path+\"300rpm oxidation and corrosion/stream2024_4_23_1_19.csv\")\n",
        "\n",
        "# 데이터 정규화 함수 정의\n",
        "def normalize_data(df):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(df)\n",
        "def concatenate_data(motor_data, sound_data):\n",
        "    return np.hstack((motor_data, sound_data))\n",
        "\n",
        "# 모터 및 소리 데이터 정규화\n",
        "normal_motor_data_normalized = normalize_data(normal_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "normal_sound_data_normalized = normalize_data(normal_data[['sound']])\n",
        "carriage_motor_data_normalized = normalize_data(carriage_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "carriage_sound_data_normalized = normalize_data(carriage_data[['sound']])\n",
        "highspeed_motor_data_normalized = normalize_data(highspeed_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "highspeed_sound_data_normalized = normalize_data(highspeed_data[['sound']])\n",
        "lack_motor_data_normalized = normalize_data(lack_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "lack_sound_data_normalized = normalize_data(lack_data[['sound']])\n",
        "corrosion_motor_data_normalized = normalize_data(corrosion_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "corrosion_sound_data_normalized = normalize_data(corrosion_data[['sound']])\n",
        "\n",
        "X_normal = concatenate_data(normal_motor_data_normalized, normal_sound_data_normalized)\n",
        "X_carriage = concatenate_data(carriage_motor_data_normalized, carriage_sound_data_normalized)\n",
        "X_highspeed = concatenate_data(highspeed_motor_data_normalized, highspeed_sound_data_normalized)\n",
        "X_lack = concatenate_data(lack_motor_data_normalized, lack_sound_data_normalized)\n",
        "X_corrosion = concatenate_data(corrosion_motor_data_normalized, corrosion_sound_data_normalized)\n",
        "\n",
        "# 레이블 생성\n",
        "y_normal = np.zeros(X_normal.shape[0])\n",
        "y_carriage = np.ones(X_carriage.shape[0])\n",
        "y_highspeed = np.full((X_highspeed.shape[0],), 2)\n",
        "y_lack = np.full((X_lack.shape[0],), 3)\n",
        "y_corrosion = np.full((X_corrosion.shape[0],), 4)\n",
        "\n",
        "# 데이터셋 합치기\n",
        "X = np.concatenate((X_normal, X_carriage, X_highspeed, X_lack, X_corrosion), axis=0)\n",
        "y = np.concatenate((y_normal, y_carriage, y_highspeed, y_lack, y_corrosion), axis=0)\n",
        "\n",
        "\n",
        "# 데이터 분할 (Train: 80%, Validation: 10%, Test: 10%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Transformer 모델 정의\n",
        "class TimeSeriesTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_encoder_layers=3, dim_feedforward=128, dropout=0.1):\n",
        "        super(TimeSeriesTransformer, self).__init__()\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout),\n",
        "            num_layers=num_encoder_layers\n",
        "        )\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        self.linear = nn.Linear(input_dim, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_len, input_dim)\n",
        "        x = self.linear(x)  # (batch_size, seq_len, d_model)\n",
        "        x = x.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
        "        x = self.encoder(x)  # (seq_len, batch_size, d_model)\n",
        "        x = x.mean(dim=0)  # (batch_size, d_model)\n",
        "        x = self.fc(x)  # (batch_size, num_classes)\n",
        "        return x\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "model = TimeSeriesTransformer(input_dim=input_dim, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# 데이터셋 및 데이터로더 생성\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 모델 학습\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # 학습\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1, input_dim)  # 입력 차원 조정\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # 검증\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.view(inputs.size(0), -1, input_dim)  # 입력 차원 조정\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1, input_dim)  # 입력 차원 조정\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# 성능 평가\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred,digits=4))\n",
        "\n",
        "# F1 스코어 계산\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'F1 Score (weighted): {f1:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ConvLSTM\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, VGAE\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import stft\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ConvLSTM 모델 정의\n",
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = kernel_size // 2\n",
        "        self.bias = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_hidden(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
        "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, num_classes, bias=True):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self.conv_lstm_cell = ConvLSTMCell(input_dim, hidden_dim, kernel_size, bias)\n",
        "        self.fc = nn.Linear(hidden_dim * input_dim, num_classes)  # hidden_dim * input_dim 크기 변경\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, height, width = x.size()\n",
        "        h, c = self.conv_lstm_cell.init_hidden(batch_size, (height, width))\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            h, c = self.conv_lstm_cell(x[:, t, :, :].unsqueeze(1), (h, c))\n",
        "\n",
        "        h = h.view(batch_size, -1)\n",
        "        out = self.fc(h)\n",
        "\n",
        "        return out\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "input_dim = 1  # 입력 채널 수 (임베딩 차원을 채널로 사용)\n",
        "hidden_dim = 64\n",
        "kernel_size = 3\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# 모델 초기화\n",
        "conv_lstm_model = ConvLSTM(input_dim, hidden_dim, kernel_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(conv_lstm_model.parameters(), lr=0.001)\n",
        "\n",
        "# 데이터셋 및 데이터로더 생성\n",
        "# 임베딩을 (batch_size, seq_len, height, width) 형태로 변환\n",
        "X_train_reshaped = torch.tensor(X_train, dtype=torch.float32).unsqueeze(2).unsqueeze(3)\n",
        "X_test_reshaped = torch.tensor(X_test, dtype=torch.float32).unsqueeze(2).unsqueeze(3)\n",
        "train_dataset = TensorDataset(X_train_reshaped, torch.tensor(y_train, dtype=torch.long))\n",
        "test_dataset = TensorDataset(X_test_reshaped, torch.tensor(y_test, dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 모델 학습\n",
        "num_epochs = 1\n",
        "conv_lstm_model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        outputs = conv_lstm_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "conv_lstm_model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = conv_lstm_model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# 성능 평가\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred,digits=4))\n",
        "\n",
        "# F1 스코어 계산\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'F1 Score (weighted): {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "JDWDnjQDm5P0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc61c861-e9d2-458a-c781-3438cea18892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Loss: 0.6155\n",
            "Accuracy: 0.73642\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6414    0.6422    0.6418     59643\n",
            "           1     0.7336    0.6888    0.7105     59988\n",
            "           2     0.9820    0.9194    0.9497     60001\n",
            "           3     0.5905    0.6576    0.6222     60196\n",
            "           4     0.7663    0.7738    0.7701     60172\n",
            "\n",
            "    accuracy                         0.7364    300000\n",
            "   macro avg     0.7428    0.7363    0.7388    300000\n",
            "weighted avg     0.7428    0.7364    0.7389    300000\n",
            "\n",
            "F1 Score (weighted): 0.7389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM AE attention\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.signal\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import LSTM, Layer, Dense, Dropout, RepeatVector, TimeDistributed, Input, LeakyReLU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight',\n",
        "                                 shape=(input_shape[-1], input_shape[-1]),\n",
        "                                 initializer='random_normal', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias',\n",
        "                                 shape=(input_shape[-1],),\n",
        "                                 initializer='zeros', trainable=True)\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return K.sum(output, axis=1)\n",
        "\n",
        "# 데이터 파일 로드\n",
        "normal_data = pd.read_csv(path+\"300rpm normal data/stream2024_4_22_23_27.csv\")\n",
        "carriage_data = pd.read_csv(path+\"300rpm carriage damage/stream2024_4_23_3_1.csv\")\n",
        "highspeed_data = pd.read_csv(path+\"300rpm high-speed damage/stream2024_4_23_0_24.csv\")\n",
        "lack_data = pd.read_csv(path+\"300rpm lack of lubrication/stream2024_4_23_2_10.csv\")\n",
        "corrosion_data = pd.read_csv(path+\"300rpm oxidation and corrosion/stream2024_4_23_1_19.csv\")\n",
        "\n",
        "# 데이터 정규화 함수 정의\n",
        "def normalize_data(df):\n",
        "    scaler = StandardScaler()\n",
        "    return scaler.fit_transform(df)\n",
        "def concatenate_data(motor_data, sound_data):\n",
        "    return np.hstack((motor_data, sound_data))\n",
        "\n",
        "# 모터 및 소리 데이터 정규화\n",
        "normal_motor_data_normalized = normalize_data(normal_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "normal_sound_data_normalized = normalize_data(normal_data[['sound']])\n",
        "carriage_motor_data_normalized = normalize_data(carriage_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "carriage_sound_data_normalized = normalize_data(carriage_data[['sound']])\n",
        "highspeed_motor_data_normalized = normalize_data(highspeed_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "highspeed_sound_data_normalized = normalize_data(highspeed_data[['sound']])\n",
        "lack_motor_data_normalized = normalize_data(lack_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "lack_sound_data_normalized = normalize_data(lack_data[['sound']])\n",
        "corrosion_motor_data_normalized = normalize_data(corrosion_data[['motor1_x', 'motor1_y', 'motor1_z']])\n",
        "corrosion_sound_data_normalized = normalize_data(corrosion_data[['sound']])\n",
        "\n",
        "\n",
        "# 레이블 생성\n",
        "y_normal = np.zeros(X_normal.shape[0])\n",
        "y_carriage = np.ones(X_carriage.shape[0])\n",
        "y_highspeed = np.full((X_highspeed.shape[0],), 2)\n",
        "y_lack = np.full((X_lack.shape[0],), 3)\n",
        "y_corrosion = np.full((X_corrosion.shape[0],), 4)\n",
        "\n",
        "# 데이터셋 합치기\n",
        "X = np.concatenate((X_normal, X_carriage, X_highspeed, X_lack, X_corrosion), axis=0)\n",
        "y = np.concatenate((y_normal, y_carriage, y_highspeed, y_lack, y_corrosion), axis=0)\n",
        "# 레이블을 원-핫 인코딩으로 변환\n",
        "y = to_categorical(y)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(\"Train data shape:\", X_train.shape)\n",
        "print(\"Test data shape:\", X_test.shape)\n",
        "\n",
        "# 데이터 형태 변환\n",
        "X_train = X_train.reshape(X_train.shape[0],-1, X_train.shape[1])  # (샘플 수, 시간, 특징 수)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1,X_test.shape[1])\n",
        "print(\"Train data shape after reshape:\", -1,X_train.shape)\n",
        "print(\"Test data shape after reshape:\", -1,X_test.shape)\n",
        "\n",
        "# LSTM Autoencoder 모델 정의 (Attention 추가)\n",
        "def create_lstm_ae_with_attention(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    encoded = LSTM(64, return_sequences=True)(inputs)\n",
        "    encoded = LSTM(32, return_sequences=True)(encoded)\n",
        "    attention = Attention()(encoded)\n",
        "    repeated = RepeatVector(input_shape[0])(attention)\n",
        "    decoded = LSTM(32, return_sequences=True)(repeated)\n",
        "    decoded = LSTM(64, return_sequences=True)(decoded)\n",
        "    outputs = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])  # (시간, 특징 수)\n",
        "model = create_lstm_ae_with_attention(input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 얼리스탑 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "\n",
        "# 모델 훈련\n",
        "print(\"Training LSTM Autoencoder model...\")\n",
        "history = model.fit(X_train, X_train, epochs=1, batch_size=256, validation_data=(X_test, X_test), callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "# LSTM Autoencoder에서 인코딩된 특징 추출\n",
        "encoder = Model(inputs=model.input, outputs=model.layers[3].output)\n",
        "\n",
        "X_train_encoded = encoder.predict(X_train)\n",
        "X_test_encoded = encoder.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# 다중 클래스 분류 모델 정의\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(64, input_shape=(X_train_encoded.shape[1],)))\n",
        "classifier.add(LeakyReLU(alpha=0.01))  # Leaky ReLU 활성화 함수 사용\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(32))\n",
        "classifier.add(LeakyReLU(alpha=0.01))  # Leaky ReLU 활성화 함수 사용\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 다중 클래스 분류 모델 훈련\n",
        "print(\"Training classifier model...\")\n",
        "history = classifier.fit(X_train_encoded, y_train, epochs=1, batch_size=256, validation_data=(X_test_encoded, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# 분류 모델 서머리\n",
        "\n",
        "\n",
        "# 테스트 데이터에 대한 예측 및 평가\n",
        "y_test_pred = classifier.predict(X_test_encoded)\n",
        "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
        "y_test_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Accuracy on test set:\", accuracy_score(y_test_true_classes, y_test_pred_classes))\n",
        "print(classification_report(y_test_true_classes, y_test_pred_classes, target_names=['Normal', 'Carriage Damage', 'High-Speed Damage', 'Lack of Lubrication', 'Oxidation and Corrosion'],digits=4))"
      ],
      "metadata": {
        "id": "jTJJglzZoA1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324bae6c-0681-4ed2-bebe-cdc7595de923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (1200000, 4)\n",
            "Test data shape: (300000, 4)\n",
            "Train data shape after reshape: -1 (1200000, 1, 4)\n",
            "Test data shape after reshape: -1 (300000, 1, 4)\n",
            "Training LSTM Autoencoder model...\n",
            "4688/4688 [==============================] - 54s 10ms/step - loss: 0.0316 - val_loss: 3.8063e-05\n",
            "37500/37500 [==============================] - 89s 2ms/step\n",
            "9375/9375 [==============================] - 22s 2ms/step\n",
            "Training classifier model...\n",
            "4688/4688 [==============================] - 22s 4ms/step - loss: 1.5715 - accuracy: 0.2508 - val_loss: 1.5036 - val_accuracy: 0.2968\n",
            "9375/9375 [==============================] - 15s 2ms/step\n",
            "Accuracy on test set: 0.29678333333333334\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                 Normal     0.3019    0.4335    0.3559     59643\n",
            "        Carriage Damage     0.2323    0.0550    0.0889     59988\n",
            "      High-Speed Damage     0.5315    0.2688    0.3570     60001\n",
            "    Lack of Lubrication     0.2316    0.3297    0.2720     60196\n",
            "Oxidation and Corrosion     0.2842    0.3974    0.3314     60172\n",
            "\n",
            "               accuracy                         0.2968    300000\n",
            "              macro avg     0.3163    0.2969    0.2811    300000\n",
            "           weighted avg     0.3163    0.2968    0.2810    300000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}